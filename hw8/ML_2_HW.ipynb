{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (404, 13)\n",
      "X_test size: (102, 13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(f'X_train size: {X_train.shape}\\nX_test size: {X_test.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for LinearRegression: 0.6687594935356307\n",
      "r2 score for Ridge: 0.666222167016852\n",
      "r2 score for Lasso: 0.6671453631686304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "models = [\n",
    "    ('LinearRegression', LinearRegression()),\n",
    "    ('Ridge', Ridge()),\n",
    "    ('Lasso', Lasso())\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    print(f'r2 score for {name}: {score}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Ridge: alpha_opt = 1e-05, r2 score = 0.6687594856409733\n",
      "GridSearchCV Lasso: alpha_opt = 1e-05, r2 score = 0.6687598638315153\n",
      "RidgeCV: alpha_opt = 1e-05, r2 score = 0.6687594856409733\n",
      "LassoCV: alpha_opt = 1e-05, r2 score = 0.6687598638315153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas = [pow(10, i) for i in range(-5, 6)]\n",
    "CV = 10\n",
    "\n",
    "models = [\n",
    "    ('GridSearchCV Ridge', Ridge()),\n",
    "    ('GridSearchCV Lasso', Lasso())\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                               param_grid=[{'alpha': alphas}],\n",
    "                               scoring='r2',\n",
    "                               cv=CV,\n",
    "                               )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    score = grid_search.score(X_test, y_test)\n",
    "    print(f\"{name}: alpha_opt = {grid_search.best_params_['alpha']}, r2 score = {score}\")\n",
    "\n",
    "models_cv = [('RidgeCV', RidgeCV(alphas=alphas, cv=CV)),\n",
    "             ('LassoCV', LassoCV(alphas=alphas, cv=CV))]\n",
    "\n",
    "for name, model in models_cv:\n",
    "    model.fit(X_train, y_train)\n",
    "    score = r2_score(y_test, model.predict(X_test))\n",
    "    print(f'{name}: alpha_opt = {model.alpha_}, r2 score = {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат немного улучшился"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax + Ridge:  r2 score = 0.6764100365423598\n",
      "MinMax + Lasso:  r2 score = 0.2573921442545195\n",
      "Standard + Ridge:  r2 score = 0.6684624359643558\n",
      "Standard + Lasso:  r2 score = 0.6239428734251422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scalers = [('MinMax', MinMaxScaler()),\n",
    "           ('Standard', StandardScaler())]\n",
    "models = [('Ridge', Ridge()),\n",
    "          ('Lasso', Lasso())]\n",
    "\n",
    "for scaler_name, scaler in scalers:\n",
    "    for model_name, model in models:\n",
    "        pipe = Pipeline([('scaler', scaler), ('model', model)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        score = pipe.score(X_test, y_test)\n",
    "        print(f\"{scaler_name} + {model_name}:  r2 score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат улучшился для MinMax + Ridge. Для остальных комбинации улучшений не видно, даже видно ухудшение для MinMax + Lasso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax + Ridge: alpha_opt = 1, r2 score = 0.6764100365423598\n",
      "MinMax + Lasso: alpha_opt = 0.01, r2 score = 0.6676993404117642\n",
      "Standard + Ridge: alpha_opt = 10, r2 score = 0.6659677905050342\n",
      "Standard + Lasso: alpha_opt = 0.01, r2 score = 0.6681815922762606\n"
     ]
    }
   ],
   "source": [
    "scalers = [('MinMax', MinMaxScaler()),\n",
    "           ('Standard', StandardScaler())]\n",
    "models = [('Ridge', Ridge()),\n",
    "          ('Lasso', Lasso())]\n",
    "\n",
    "for scaler_name, scaler in scalers:\n",
    "    for model_name, model in models:\n",
    "        pipe = Pipeline([('scaler', scaler), ('model', model)])\n",
    "        grid_search = GridSearchCV(pipe, param_grid=[{'model__alpha': alphas}], scoring='r2', cv=CV)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        score = grid_search.score(X_test, y_test)\n",
    "        print(\n",
    "            f\"{scaler_name} + {model_name}: alpha_opt = {grid_search.best_params_['model__alpha']}, r2 score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат улучшился для MinMax + Ridge. Для остальных комбинации улучшений не видно."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax + Ridge + feature mults without feature squares: alpha_opt = 0.01, r2 score = 0.8572252837848734\n",
      "MinMax + Ridge + feature mults + feature squares: alpha_opt = 0.01, r2 score = 0.833535855503777\n",
      "MinMax + Lasso + feature mults without feature squares: alpha_opt = 0.0001, r2 score = 0.840169780674503\n",
      "MinMax + Lasso + feature mults + feature squares: alpha_opt = 0.001, r2 score = 0.8390581680518306\n",
      "Standard + Ridge + feature mults without feature squares: alpha_opt = 10, r2 score = 0.8496468217328311\n",
      "Standard + Ridge + feature mults + feature squares: alpha_opt = 10, r2 score = 0.818046587724366\n",
      "Standard + Lasso + feature mults without feature squares: alpha_opt = 0.01, r2 score = 0.8509794967776149\n",
      "Standard + Lasso + feature mults + feature squares: alpha_opt = 0.01, r2 score = 0.8138518691835619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "scalers = [('MinMax', MinMaxScaler()),\n",
    "           ('Standard', StandardScaler())]\n",
    "models = [('Ridge', Ridge()),\n",
    "          ('Lasso', Lasso())]\n",
    "polyfeatures = [('feature mults without feature squares', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "                ('feature mults + feature squares', PolynomialFeatures(degree=2))]\n",
    "\n",
    "for scaler_name, scaler in scalers:\n",
    "    for model_name, model in models:\n",
    "        for polyf_name, polyfeature in polyfeatures:\n",
    "            pipe = Pipeline([('scaler', scaler), ('poly', polyfeature), ('model', model)])\n",
    "            grid_search = GridSearchCV(pipe, param_grid=[{'model__alpha': alphas}], scoring='r2', cv=CV)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            score = grid_search.score(X_test, y_test)\n",
    "            print(\n",
    "                f\"{scaler_name} + {model_name} + {polyf_name}: alpha_opt = {grid_search.best_params_['model__alpha']}, r2 score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат существенно улучшился для всех комбинаций"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_scaler: StandardScaler()\n",
      "opt_poly:PolynomialFeatures(interaction_only=True)\n",
      "opt_model:Ridge(alpha=10)\n",
      "opt_score:0.8496468217328311\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(scaler=[None, MinMaxScaler(), StandardScaler()],\n",
    "                  poly=[None, PolynomialFeatures(degree=2, interaction_only=True), PolynomialFeatures(degree=2)],\n",
    "                  model=[Ridge(), Lasso()],\n",
    "                  model__alpha=alphas)\n",
    "\n",
    "pipe = Pipeline([('scaler', 'passthrough'), ('poly', 'passthrough'), ('model', 'passthrough')])\n",
    "grid_search = GridSearchCV(pipe, param_grid, scoring='r2', cv=CV)\n",
    "grid_search.fit(X_train, y_train)\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(f\"opt_scaler: {grid_search.best_params_['scaler']}\\n\"\n",
    "      f\"opt_poly:{grid_search.best_params_['poly']}\\n\"\n",
    "      f\"opt_model:{grid_search.best_params_['model']}\\n\"\n",
    "      f\"opt_score:{score}\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   0                 1       2          3   4                   5   \\\n0  39         State-gov   77516  Bachelors  13       Never-married   \n1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n2  38           Private  215646    HS-grad   9            Divorced   \n3  53           Private  234721       11th   7  Married-civ-spouse   \n4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n\n                  6              7      8       9     10  11  12  \\\n0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n1    Exec-managerial        Husband  White    Male     0   0  13   \n2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n4     Prof-specialty           Wife  Black  Female     0   0  40   \n\n              13     14  \n0  United-States  <=50K  \n1  United-States  <=50K  \n2  United-States  <=50K  \n3  United-States  <=50K  \n4           Cuba  <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "N = len(df.columns)\n",
    "X = df.iloc[:, :N - 1]\n",
    "y = df.iloc[:, -1].apply(lambda x: 1.0 if x == '>50K' else 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape == df.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: пропуски отсутствуют"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical:[1, 3, 5, 6, 7, 8, 9, 13],\n",
      "non-categorical:[0, 2, 4, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "\n",
    "max_n_unique = 0.000005 * df.shape[0]\n",
    "cat, non_cat = [], []\n",
    "for col in X.columns:\n",
    "    if df[col].nunique() < max_n_unique or is_string_dtype(df[col]):\n",
    "        cat.append(col)\n",
    "    else:\n",
    "        non_cat.append(col)\n",
    "\n",
    "print(f'categorical:{cat},\\nnon-categorical:{non_cat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        0         1         2        3    4         5    6    7    8    9    \\\n0  0.301370  0.044131  0.800000  0.02174  0.0  0.397959  0.0  0.0  0.0  0.0   \n1  0.452055  0.048052  0.800000  0.00000  0.0  0.122449  0.0  0.0  0.0  0.0   \n2  0.287671  0.137581  0.533333  0.00000  0.0  0.397959  0.0  0.0  0.0  0.0   \n3  0.493151  0.150486  0.400000  0.00000  0.0  0.397959  0.0  0.0  0.0  0.0   \n4  0.150685  0.220635  0.800000  0.00000  0.0  0.397959  0.0  0.0  0.0  0.0   \n\n   ...  98   99   100  101  102  103  104  105  106  107  \n0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n\n[5 rows x 108 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n      <th>103</th>\n      <th>104</th>\n      <th>105</th>\n      <th>106</th>\n      <th>107</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.301370</td>\n      <td>0.044131</td>\n      <td>0.800000</td>\n      <td>0.02174</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.452055</td>\n      <td>0.048052</td>\n      <td>0.800000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.122449</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.287671</td>\n      <td>0.137581</td>\n      <td>0.533333</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.493151</td>\n      <td>0.150486</td>\n      <td>0.400000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.150685</td>\n      <td>0.220635</td>\n      <td>0.800000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 108 columns</p>\n</div>"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "t = [('num', MinMaxScaler(), non_cat), ('cat', OneHotEncoder(), cat)]\n",
    "transformer = ColumnTransformer(transformers=t)\n",
    "X_train1_sparse = transformer.fit_transform(X.copy())\n",
    "X1 = pd.DataFrame(X_train1_sparse.toarray())\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9335486475575293\n",
      "f1 score(weighted):0.9656324383012485\n",
      "f1 score(binary):0.0\n",
      "f1 score(micro):0.9335486475575293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "most_freq_val = y.value_counts().idxmax()\n",
    "X1_most_freq_train = X1.loc[y == most_freq_val]\n",
    "y1_most_freq = y.loc[y == most_freq_val]\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X1_train, y1_train)\n",
    "y1_pred = log_reg.predict(X1_most_freq_train)\n",
    "accuracy = accuracy_score(y1_most_freq, y1_pred)\n",
    "f1_score_w = f1_score(y1_most_freq, y1_pred, average='weighted')\n",
    "f1_score_b = f1_score(y1_most_freq, y1_pred, average='binary')\n",
    "f1_score_m = f1_score(y1_most_freq, y1_pred, average='micro')\n",
    "print(\n",
    "    f'accuracy: {accuracy}\\nf1 score(weighted):{f1_score_w}\\nf1 score(binary):{f1_score_b}\\nf1 score(micro):{f1_score_m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), metric: accuracy, score: 0.8512346961272244\n",
      "model: LogisticRegression(), metric: f1, score: 0.6565786295140361\n",
      "model: LogisticRegression(), metric: f1_weighted, score: 0.8455935113447877\n",
      "model: SVC(), metric: accuracy, score: 0.8410180549023947\n",
      "model: SVC(), metric: f1, score: 0.6225568402859734\n",
      "model: SVC(), metric: f1_weighted, score: 0.8330788126531405\n",
      "model: LinearSVC(), metric: accuracy, score: 0.852667876306566\n",
      "model: LinearSVC(), metric: f1, score: 0.6571268426576358\n",
      "model: LinearSVC(), metric: f1_weighted, score: 0.8465790827177206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = [LogisticRegression(), SVC(), LinearSVC()]\n",
    "metrics = ['accuracy', 'f1', 'f1_weighted']\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        score = cross_val_score(model, X1, y, cv=CV, scoring=metric).mean()\n",
    "        print(f'model: {model}, metric: {metric}, score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   0                 1       2          3   4                   5   \\\n0  39         State-gov   77516  Bachelors  13       Never-married   \n1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n2  38           Private  215646    HS-grad   9            Divorced   \n3  53           Private  234721       11th   7  Married-civ-spouse   \n4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n\n                  6              7      8       9     10 11  12             13  \n0       Adm-clerical  Not-in-family  White    Male  2174  0  40  United-States  \n1    Exec-managerial        Husband  White    Male     0  0  13  United-States  \n2  Handlers-cleaners  Not-in-family  White    Male     0  0  40  United-States  \n3  Handlers-cleaners        Husband  Black    Male     0  0  40  United-States  \n4     Prof-specialty           Wife  Black  Female     0  0  40           Cuba  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "inputer = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "inputer = inputer.fit_transform(X.copy())\n",
    "X_cleared = pd.DataFrame(inputer)\n",
    "X_cleared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), metric: accuracy, score: 0.8506613578312656\n",
      "model: LogisticRegression(), metric: f1, score: 0.6538921995821159\n",
      "model: LogisticRegression(), metric: f1_weighted, score: 0.844751954713187\n",
      "model: LinearSVC(), metric: accuracy, score: 0.8511322874935976\n",
      "model: LinearSVC(), metric: f1, score: 0.6517974174872275\n",
      "model: LinearSVC(), metric: f1_weighted, score: 0.8446589797120246\n"
     ]
    }
   ],
   "source": [
    "X_cleared_sparse = transformer.fit_transform(X_cleared.copy())\n",
    "X2 = pd.DataFrame(X_cleared_sparse.toarray())\n",
    "\n",
    "models = [LogisticRegression(), LinearSVC()]\n",
    "metrics = ['accuracy', 'f1', 'f1_weighted']\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        score = cross_val_score(model, X2, y, cv=CV, scoring=metric).mean()\n",
    "        print(f'model: {model}, metric: {metric}, score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат немного ухудшился"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), metric: accuracy, score: 0.8471099407099377\n",
      "model: LogisticRegression(), metric: f1, score: 0.6604622598607446\n",
      "model: LogisticRegression(), metric: f1_weighted, score: 0.8416385190841975\n",
      "model: LinearSVC(), metric: accuracy, score: 0.8483703520157381\n",
      "model: LinearSVC(), metric: f1, score: 0.6613169761301343\n",
      "model: LinearSVC(), metric: f1_weighted, score: 0.8425843851728692\n"
     ]
    }
   ],
   "source": [
    "X_dropped = df.copy().replace('?', np.nan).dropna()\n",
    "X1_dropped = X_dropped.iloc[:, :N - 1]\n",
    "y = X_dropped.iloc[:, -1].apply(lambda x: 1.0 if x == '>50K' else 0.0)\n",
    "\n",
    "X1_dropped_sparse = transformer.fit_transform(X1_dropped)\n",
    "X2_dropped = pd.DataFrame(X1_dropped_sparse.toarray())\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        score = cross_val_score(model, X2_dropped, y, cv=CV, scoring=metric).mean()\n",
    "        print(f'model: {model}, metric: {metric}, score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: результат почти не поменялся, немного ухудшился"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RandomForestClassifier(), metric: accuracy, score: 0.849829785411494\n",
      "model: RandomForestClassifier(), metric: f1, score: 0.6732926772674385\n",
      "model: RandomForestClassifier(), metric: f1_weighted, score: 0.8451934096014349\n",
      "model: GradientBoostingClassifier(), metric: accuracy, score: 0.8630314878898486\n",
      "model: GradientBoostingClassifier(), metric: f1, score: 0.6880056062412362\n",
      "model: GradientBoostingClassifier(), metric: f1_weighted, score: 0.8566734586197544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "models = [RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        score = cross_val_score(model, X2_dropped, y, cv=CV, scoring=metric).mean()\n",
    "        print(f'model: {model}, metric: {metric}, score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: по всем метрикам GradientBoostingClassifier превосходит остальные модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_scaler: MinMaxScaler()\n",
      "opt_model:GradientBoostingClassifier()\n",
      "opt_score:0.8574716304043987\n",
      "opt_scaler: MinMaxScaler()\n",
      "opt_model:GradientBoostingClassifier()\n",
      "opt_score:0.8585161877534656\n",
      "{'opt': 'drop', 'score': 0.8585161877534656, 'param': {'model': GradientBoostingClassifier(), 'scaler': MinMaxScaler()}}\n"
     ]
    }
   ],
   "source": [
    "def clearData(data, opt):\n",
    "    N = len(data.columns)\n",
    "    df = data.copy()\n",
    "    if opt == 'clear':\n",
    "        inputer = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "        X = df.iloc[:, :N - 1]\n",
    "        X_to_split = pd.DataFrame(inputer.fit_transform(X))\n",
    "        y = df.iloc[:, -1].apply(lambda x: 1.0 if x == '>50K' else 0.0)\n",
    "    else:\n",
    "        X_dr = df.copy().replace('?', np.nan).dropna()\n",
    "        X_to_split = X_dr.iloc[:, :N - 1]\n",
    "        y = X_dr.iloc[:, -1].apply(lambda x: 1.0 if x == '>50K' else 0.0)\n",
    "\n",
    "    return X_to_split, y\n",
    "\n",
    "\n",
    "t = [('cat', OneHotEncoder(), cat)]\n",
    "scalers = [MinMaxScaler(), StandardScaler()]\n",
    "models = [LogisticRegression(), LinearSVC(), RandomForestClassifier(), GradientBoostingClassifier()]\n",
    "param_grid = dict(scaler=scalers, model=models)\n",
    "pipe = Pipeline([('scaler', 'passthrough'), ('model', 'passthrough')])\n",
    "opts = ['clear', 'drop']\n",
    "scoring = ['accuracy', 'f1']\n",
    "opt_list = []\n",
    "\n",
    "for opt in opts:\n",
    "    X, y = clearData(df, opt)\n",
    "    X_sparse = ColumnTransformer(transformers=t, remainder=\"passthrough\").fit_transform(X.copy())\n",
    "    X1 = pd.DataFrame(X_sparse.toarray())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "    grid_search = GridSearchCV(pipe, param_grid, scoring='f1_weighted', cv=CV)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    score = grid_search.score(X_test, y_test)\n",
    "\n",
    "    opt_list.append({'opt': opt, 'score': score, 'param': grid_search.best_params_})\n",
    "    print(f\"opt_scaler: {grid_search.best_params_['scaler']}\\n\"\n",
    "          f\"opt_model:{grid_search.best_params_['model']}\\n\"\n",
    "          f\"opt_score:{score}\"\n",
    "          )\n",
    "opt_params = opt_list[0] if opt_list[0]['score'] > opt_list[1]['score'] else opt_list[1]\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8650082918739636, f1: 0.6981458590852905\n"
     ]
    }
   ],
   "source": [
    "opt_opt = opt_params['opt']\n",
    "scaler_opt = opt_params['param']['scaler']\n",
    "model_opt = opt_params['param']['model']\n",
    "\n",
    "X, y = clearData(df, opt_opt)\n",
    "X_sparse = ColumnTransformer(transformers=t, remainder=\"passthrough\").fit_transform(X.copy())\n",
    "X1 = pd.DataFrame(X_sparse.toarray())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "pipe_opt = Pipeline([('scaler', scaler_opt), ('model', model_opt)])\n",
    "pipe_opt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_opt.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'accuracy: {accuracy}, f1: {f1}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}