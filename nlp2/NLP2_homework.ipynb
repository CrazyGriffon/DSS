{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "NLP2-homework",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### NLP2_1 https://www.hackerrank.com/challenges/detect-the-email-addresses/problem?isFullScreen=true"
   ],
   "metadata": {
    "id": "OYZRf1ncz-sT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "\n",
    "def print_matches(pattern, file_path):\n",
    "    matches = set()\n",
    "    with open(file_path, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            matches.update(regex.findall(pattern, line))\n",
    "    for match in matches:\n",
    "        print(match)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interviewstreet@hackerrank.com\n",
      "hackers@hackerrank.com\n",
      "product@hackerrank.com\n"
     ]
    }
   ],
   "source": [
    "s = '[a-zA-Z0-9_.]*'\n",
    "pattern = regex.compile(rf'{s}@{s}')\n",
    "print_matches(pattern, \"./text1.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP2_2 https://www.hackerrank.com/challenges/detect-the-domain-name/problem?isFullScreen=true"
   ],
   "metadata": {
    "id": "jKzbIfdq0CKr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "askoxford.com\n",
      "bnsf.com\n",
      "hydrogencarsnow.com\n",
      "web.archive.org\n",
      "mrvc.indianrail.gov.in\n"
     ]
    }
   ],
   "source": [
    "pattern = regex.compile(r'https?:\\/\\/(?:www.|ww2.)?([^\\/]*)\\/')\n",
    "print_matches(pattern, \"./text2.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML1_4: Реализовать stemming, lemmatization & BoW на следующем датасете: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK (Russian Toxic-abuse comments)\n",
    "#### https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments\n",
    "#### Дубликат файла: https://cloud.mail.ru/public/Z4L3/vB8GcgTtK\n",
    "\n"
   ],
   "metadata": {
    "id": "b5DQQnoU1bXY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "with open(\"./labeled.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    data = [comment for [comment, toxic] in reader]\n",
    "\n",
    "data = data[1:]"
   ],
   "metadata": {
    "id": "0BRC1-k81pIW"
   },
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Верблюдов', '-', 'то', 'за', 'что', '?', 'Дебилы', ',', 'бл', '...']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "data_tok = []\n",
    "for sentence in data:\n",
    "    data_tok.append(tokenizer.tokenize(sentence.lower()))\n",
    "\n",
    "print(tokenizer.tokenize(data[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 33932), ('.', 26863), ('и', 12684), ('в', 11974), ('не', 10301), ('-', 7906), ('на', 7003), ('что', 5986), ('а', 5008), ('?', 4395)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "lemms = []\n",
    "for words in data_tok:\n",
    "    gen = (lemmatizer.lemmatize(word) for word in words)\n",
    "    lemms.extend(gen)\n",
    "\n",
    "counter = Counter(lemms)\n",
    "dictionary = dict(counter)\n",
    "print(counter.most_common(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(language=\"russian\")\n",
    "stemmed = []\n",
    "\n",
    "for words in data_tok:\n",
    "    d = [stemmer.stem(word) for word in words]\n",
    "    stemmed.extend(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words:  68638\n",
      "after lemmatization:  68602\n",
      "after stemming:  33642\n",
      "\"и\" встречается 12684 раз\n"
     ]
    }
   ],
   "source": [
    "flat_list = [word for words in data_tok for word in words]\n",
    "\n",
    "print('total number of words: ', len(set(flat_list)))\n",
    "print('after lemmatization: ', len(set(lemms)))\n",
    "print('after stemming: ', len(set(stemmed)))\n",
    "\n",
    "vocabulary = dict(Counter(flat_list))  #словарь для BoW\n",
    "\n",
    "#special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
    "#for key in special_char:\n",
    "#          vocabulary.pop(key, None)\n",
    "\n",
    "word_to_search = 'и'\n",
    "print(f'\"{word_to_search}\" встречается {vocabulary[word_to_search]} раз')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 20 элементов словаря:\n",
      "верблюдов\n",
      "-\n",
      "то\n",
      "за\n",
      "что\n",
      "?\n",
      "дебилы\n",
      ",\n",
      "бл\n",
      "...\n",
      "хохлы\n",
      "это\n",
      "отдушина\n",
      "затюканого\n",
      "россиянина\n",
      "мол\n",
      "вон\n",
      "а\n",
      "у\n",
      "хохлов\n",
      "еще\n",
      "хуже\n",
      "Токены комментария:['верблюдов', '-', 'то', 'за', 'что', '?', 'дебилы', ',', 'бл', '...']\n",
      "Первые 20 компонент вектора слов, соответствующего комментарию:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def vectorize(tokens):\n",
    "    return [tokens.count(w) for w in vocabulary]\n",
    "\n",
    "\n",
    "n = 20\n",
    "k = 20\n",
    "print(f'Первые {n} элементов словаря:')\n",
    "for i, (key, value) in enumerate(vocabulary.items()):\n",
    "    print(key)\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "comment = data_tok[0]\n",
    "print(f'Токены комментария:{comment}')\n",
    "bow_vector = vectorize(comment)\n",
    "print(f'Первые {k} компонент вектора слов, соответствующего комментарию:{bow_vector[:k]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68423\n",
      "Верблюдов-то за что? Дебилы, бл...  : 6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "word_count = vectorizer.fit_transform(data)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print(f'{data[0][:-1]}  : {sum(word_count.toarray()[0])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "            idf_weights\nобновиться     9.882739\nпещеры         9.882739\nпечёнку        9.882739\nпешеблядь      9.882739\nпешее          9.882739\n...                 ...\nто             2.639941\nэто            2.575201\nчто            2.295682\nна             2.169848\nне             1.860826\n\n[68423 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idf_weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>обновиться</th>\n      <td>9.882739</td>\n    </tr>\n    <tr>\n      <th>пещеры</th>\n      <td>9.882739</td>\n    </tr>\n    <tr>\n      <th>печёнку</th>\n      <td>9.882739</td>\n    </tr>\n    <tr>\n      <th>пешеблядь</th>\n      <td>9.882739</td>\n    </tr>\n    <tr>\n      <th>пешее</th>\n      <td>9.882739</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>то</th>\n      <td>2.639941</td>\n    </tr>\n    <tr>\n      <th>это</th>\n      <td>2.575201</td>\n    </tr>\n    <tr>\n      <th>что</th>\n      <td>2.295682</td>\n    </tr>\n    <tr>\n      <th>на</th>\n      <td>2.169848</td>\n    </tr>\n    <tr>\n      <th>не</th>\n      <td>1.860826</td>\n    </tr>\n  </tbody>\n</table>\n<p>68423 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=vectorizer.get_feature_names(), columns=[\"idf_weights\"])\n",
    "df_idf.sort_values(by=['idf_weights'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "              tfidf\nверблюдов  0.613101\nбл         0.558288\nдебилы     0.470959\nза         0.198487\nто         0.170782\n...             ...\nкиселева   0.000000\nкиселевым  0.000000\nкиселем    0.000000\nкисель     0.000000\nётавских   0.000000\n\n[68423 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>верблюдов</th>\n      <td>0.613101</td>\n    </tr>\n    <tr>\n      <th>бл</th>\n      <td>0.558288</td>\n    </tr>\n    <tr>\n      <th>дебилы</th>\n      <td>0.470959</td>\n    </tr>\n    <tr>\n      <th>за</th>\n      <td>0.198487</td>\n    </tr>\n    <tr>\n      <th>то</th>\n      <td>0.170782</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>киселева</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>киселевым</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>киселем</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>кисель</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>ётавских</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>68423 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector = tfidf_transformer.transform(word_count)\n",
    "first_document_vector = tf_idf_vector[0]\n",
    "df_tfifd = pd.DataFrame(first_document_vector.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df_tfifd.sort_values(by=[\"tfidf\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "              tfidf\nверблюдов  0.613101\nбл         0.558288\nдебилы     0.470959\nза         0.198487\nто         0.170782\n...             ...\nкиселева   0.000000\nкиселевым  0.000000\nкиселем    0.000000\nкисель     0.000000\nётавских   0.000000\n\n[68423 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>верблюдов</th>\n      <td>0.613101</td>\n    </tr>\n    <tr>\n      <th>бл</th>\n      <td>0.558288</td>\n    </tr>\n    <tr>\n      <th>дебилы</th>\n      <td>0.470959</td>\n    </tr>\n    <tr>\n      <th>за</th>\n      <td>0.198487</td>\n    </tr>\n    <tr>\n      <th>то</th>\n      <td>0.170782</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>киселева</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>киселевым</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>киселем</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>кисель</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>ётавских</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>68423 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfIdfVectorizer=TfidfVectorizer(smooth_idf=True, use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(data)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}